# ğŸ“° Dantri News Crawler

**Dantri News Crawler** lÃ  má»™t dá»± Ã¡n Python dÃ¹ng Ä‘á»ƒ tá»± Ä‘á»™ng thu tháº­p tin tá»©c tá»« trang bÃ¡o Ä‘iá»‡n tá»­ [DÃ¢n TrÃ­](https://dantri.com.vn). Dá»± Ã¡n sá»­ dá»¥ng káº¿t há»£p giá»¯a ká»¹ thuáº­t **HTTP Request + HTML Parsing** vÃ  **Selenium Headless** Ä‘á»ƒ xá»­ lÃ½ ná»™i dung Ä‘á»™ng trÃªn trang.

---

## ğŸ“¦ Cáº¥u trÃºc thÆ° má»¥c

```
crawl_dantri/
â”œâ”€â”€ data/                    # LÆ°u dá»¯ liá»‡u sau khi crawl
â”œâ”€â”€ src/
â”‚   â””â”€â”€ crawler/
â”‚       â”œâ”€â”€ base.py          # Lá»›p crawler cÆ¡ sá»Ÿ
â”‚       â”œâ”€â”€ utils.py         # HÃ m tiá»‡n Ã­ch (log, xá»­ lÃ½ chuá»—i, etc.)
â”‚       â”œâ”€â”€ config.py        # CÃ¡c thÃ´ng sá»‘ cáº¥u hÃ¬nh (sleep time, pagination...)
â”‚       â””â”€â”€ dantri/
â”‚           â””â”€â”€ dantri.py    # Crawler chÃ­nh cho trang DÃ¢n TrÃ­
â”œâ”€â”€ crawl_log.txt            # File ghi log quÃ¡ trÃ¬nh crawl
â”œâ”€â”€ main.py                  # Cháº¡y crawl vÃ  lÆ°u káº¿t quáº£
â”œâ”€â”€ worker.py                # Quáº£n lÃ½ Ä‘a luá»“ng hoáº·c queue
â”œâ”€â”€ eval.ipynb               # PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘Ã£ crawl
â”œâ”€â”€ run_crawl.bat            # Batch file Ä‘á»ƒ cháº¡y crawler
â””â”€â”€ requirements.txt         # CÃ¡c thÆ° viá»‡n cáº§n cÃ i Ä‘áº·t
```

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng áº£o
#### 1.1. Táº¡o mÃ´i trÆ°á»ng cháº¡y áº£o (náº¿u chÆ°a cÃ³)
```bash
conda -n create bigdata-env python=3.10
```
#### 1.2. KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o
```bash
conda activate bigdata-env
```
### 2. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
pip install -r requirements.txt
```

### 3. Cháº¡y crawler

```bash
python main.py sync --num_links 100 --max_pagination 5
```

### 4. (TÃ¹y chá»n) Cháº¡y báº±ng batch trÃªn Windows

```bash
run_crawler_vnexpress.bat
```

---

## âš™ï¸ CÃ¡c ká»¹ thuáº­t sá»­ dá»¥ng

| Ká»¹ thuáº­t                  | MÃ´ táº£ |
|---------------------------|-------|
| **Selenium + Headless**   | Scroll trang `Tin Má»›i Nháº¥t` Ä‘á»ƒ láº¥y dá»¯ liá»‡u Ä‘á»™ng |
| **BeautifulSoup**         | PhÃ¢n tÃ­ch cáº¥u trÃºc DOM vÃ  trÃ­ch xuáº¥t ná»™i dung HTML |
| **Äá»‡ quy phÃ¢n trang**     | Láº·p qua cÃ¡c trang `p1`, `p2`, ... trong má»—i chuyÃªn má»¥c |
| **Slugify**               | Chuyá»ƒn tÃªn chuyÃªn má»¥c thÃ nh dáº¡ng slug (Ä‘á»ƒ Ä‘áº·t key) |
| **TQDM**                  | Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh crawl |
| **Cáº¥u hÃ¬nh Ä‘á»™ng**         | ThÃ´ng qua `config.py` Ä‘á»ƒ thay Ä‘á»•i sleep time, max page, v.v |

---

## ğŸ“Š Äáº§u ra

Dá»¯ liá»‡u sau khi crawl Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c `data/`, cÃ³ thá»ƒ á»Ÿ dáº¡ng `.csv`, `.json`, hoáº·c Ä‘Æ°a vÃ o notebook `eval.ipynb` Ä‘á»ƒ trá»±c quan hÃ³a.

---

## ğŸ“Œ TÃ¡c giáº£

- ğŸ‘¨â€ğŸ’» **LÃª Háº£i Yáº¿n**
- ğŸ“˜ TrÆ°á»ng Äáº¡i há»c Phenikaa
- ğŸ” LiÃªn há»‡ há»— trá»£: [GitHub](https://github.com/)

---

## ğŸ› ï¸ TODOs

- [ ] Crawl áº£nh Ä‘Ã­nh kÃ¨m bÃ i viáº¿t
- [ ] Crawl bÃ¬nh luáº­n (náº¿u cÃ³)
- [ ] Há»— trá»£ crawl cÃ¡c bÃ¡o khÃ¡c (VNExpress, Tuá»•i Tráº»...)
- [ ] ThÃªm lá»‹ch tá»± Ä‘á»™ng báº±ng Jenkins hoáº·c cronjob

---